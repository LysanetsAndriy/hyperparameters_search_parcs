================================================================================
GRID SEARCH RESULTS: MobileNetV2 on CIFAR-10
================================================================================

Total Configurations: 32
Successful: 32
Failed: 0

================================================================================
BEST CONFIGURATION
================================================================================
Config ID: 9
Learning Rate: 0.0005
Batch Size: 32
Optimizer: ADAM
Weight Decay: 0.0
Best Validation Accuracy: 56.67%
Final Training Loss: 0.4484
Training Time: 6.6s
Worker ID: 0
Trained on: Tesla T4

================================================================================
ALL RESULTS (Sorted by Validation Accuracy)
================================================================================

Rank | Config |    LR     | Batch | Opt  |    WD     | Time(s) |  Loss  | Val Acc | Device
-----|--------|-----------|-------|------|-----------|---------|--------|---------|-------
   1 |      9 |    0.0005 |    32 | adam |   0.00000 |     6.6 | 0.4484 |   56.67% | cpu
   2 |     13 |    0.0010 |    32 | adam |   0.00000 |     6.7 | 0.5638 |   56.67% | cpu
   3 |      7 |    0.0003 |    64 | adam |   0.00000 |     4.1 | 0.1845 |   55.00% | cpu
   4 |     16 |    0.0030 |    32 | sgd  |   0.00000 |     6.4 | 0.4505 |   55.00% | cpu
   5 |      5 |    0.0003 |    32 | adam |   0.00000 |     6.6 | 0.3130 |   53.67% | cpu
   6 |     15 |    0.0010 |    64 | adam |   0.00000 |     4.0 | 0.3181 |   53.67% | cpu
   7 |     11 |    0.0005 |    64 | adam |   0.00000 |     4.1 | 0.2576 |   53.33% | cpu
   8 |     18 |    0.0030 |    64 | sgd  |   0.00000 |     3.9 | 0.3047 |   53.33% | cpu
   9 |      1 |    0.0001 |    32 | adam |   0.00000 |     6.6 | 0.5512 |   52.33% | cpu
  10 |     22 |    0.0050 |    64 | sgd  |   0.00000 |     4.1 | 0.3562 |   52.33% | cpu
  11 |     26 |    0.0100 |    64 | sgd  |   0.00000 |     3.8 | 0.5323 |   50.67% | cpu
  12 |     19 |    0.0030 |    64 | adam |   0.00000 |     4.2 | 0.6523 |   49.33% | cpu
  13 |      8 |    0.0005 |    32 | sgd  |   0.00000 |     6.3 | 0.9897 |   47.67% | cpu
  14 |     17 |    0.0030 |    32 | adam |   0.00000 |     6.7 | 1.0962 |   47.33% | cpu
  15 |     20 |    0.0050 |    32 | sgd  |   0.00000 |     6.2 | 0.6482 |   47.33% | cpu
  16 |     12 |    0.0010 |    32 | sgd  |   0.00000 |     6.4 | 0.7805 |   46.67% | cpu
  17 |      3 |    0.0001 |    64 | adam |   0.00000 |     4.1 | 0.5241 |   46.00% | cpu
  18 |     10 |    0.0005 |    64 | sgd  |   0.00000 |     4.5 | 1.3713 |   45.33% | cpu
  19 |     24 |    0.0100 |    32 | sgd  |   0.00000 |     6.2 | 0.8414 |   44.67% | cpu
  20 |      4 |    0.0003 |    32 | sgd  |   0.00000 |     6.3 | 1.3522 |   44.33% | cpu
  21 |     14 |    0.0010 |    64 | sgd  |   0.00000 |     3.9 | 0.8847 |   44.33% | cpu
  22 |     23 |    0.0050 |    64 | adam |   0.00000 |     4.0 | 0.9582 |   42.67% | cpu
  23 |     30 |    0.0300 |    64 | sgd  |   0.00000 |     3.9 | 0.9993 |   39.67% | cpu
  24 |     21 |    0.0050 |    32 | adam |   0.00000 |     7.2 | 1.2830 |   36.67% | cpu
  25 |      6 |    0.0003 |    64 | sgd  |   0.00000 |     3.9 | 1.6773 |   36.33% | cpu
  26 |     27 |    0.0100 |    64 | adam |   0.00000 |     4.2 | 1.5974 |   34.00% | cpu
  27 |      0 |    0.0001 |    32 | sgd  |   0.00000 |     6.5 | 1.9430 |   32.33% | cpu
  28 |     25 |    0.0100 |    32 | adam |   0.00000 |     6.6 | 1.6338 |   31.00% | cpu
  29 |     28 |    0.0300 |    32 | sgd  |   0.00000 |     6.3 | 1.6115 |   30.33% | cpu
  30 |     31 |    0.0300 |    64 | adam |   0.00000 |     4.1 | 2.0077 |   23.67% | cpu
  31 |      2 |    0.0001 |    64 | sgd  |   0.00000 |     4.0 | 2.1082 |   22.33% | cpu
  32 |     29 |    0.0300 |    32 | adam |   0.00000 |     6.6 | 2.1072 |   21.33% | cpu

================================================================================
DETAILED WORKER LOGS
================================================================================

[Worker 0] Config 0 started
[Worker 0] Params: {'config_id': 0, 'learning_rate': 0.0001, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.4190, Val Acc=10.00%
[Worker 0] Epoch 2/10: Loss=2.3399, Val Acc=14.00%
[Worker 0] Epoch 3/10: Loss=2.2966, Val Acc=15.00%
[Worker 0] Epoch 4/10: Loss=2.2183, Val Acc=19.33%
[Worker 0] Epoch 5/10: Loss=2.1965, Val Acc=19.67%
[Worker 0] Epoch 6/10: Loss=2.1262, Val Acc=24.00%
[Worker 0] Epoch 7/10: Loss=2.0880, Val Acc=26.67%
[Worker 0] Epoch 8/10: Loss=2.0396, Val Acc=27.33%
[Worker 0] Epoch 9/10: Loss=2.0284, Val Acc=30.67%
[Worker 0] Epoch 10/10: Loss=1.9430, Val Acc=32.33%
[Worker 0] Training completed in 6.5s, Best Val Acc: 32.33%
[Worker 0] Config 1 started
[Worker 0] Params: {'config_id': 1, 'learning_rate': 0.0001, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.2882, Val Acc=20.33%
[Worker 0] Epoch 2/10: Loss=1.9022, Val Acc=39.33%
[Worker 0] Epoch 3/10: Loss=1.6593, Val Acc=41.67%
[Worker 0] Epoch 4/10: Loss=1.3927, Val Acc=43.00%
[Worker 0] Epoch 5/10: Loss=1.2086, Val Acc=46.33%
[Worker 0] Epoch 6/10: Loss=1.0312, Val Acc=47.33%
[Worker 0] Epoch 7/10: Loss=0.8658, Val Acc=47.33%
[Worker 0] Epoch 8/10: Loss=0.7754, Val Acc=49.67%
[Worker 0] Epoch 9/10: Loss=0.6381, Val Acc=52.33%
[Worker 0] Epoch 10/10: Loss=0.5512, Val Acc=51.00%
[Worker 0] Training completed in 6.6s, Best Val Acc: 52.33%
[Worker 0] Config 2 started
[Worker 0] Params: {'config_id': 2, 'learning_rate': 0.0001, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.4359, Val Acc=7.33%
[Worker 0] Epoch 2/10: Loss=2.3939, Val Acc=8.67%
[Worker 0] Epoch 3/10: Loss=2.3267, Val Acc=11.33%
[Worker 0] Epoch 4/10: Loss=2.2960, Val Acc=12.67%
[Worker 0] Epoch 5/10: Loss=2.2637, Val Acc=14.33%
[Worker 0] Epoch 6/10: Loss=2.2159, Val Acc=17.33%
[Worker 0] Epoch 7/10: Loss=2.1984, Val Acc=17.00%
[Worker 0] Epoch 8/10: Loss=2.1590, Val Acc=18.00%
[Worker 0] Epoch 9/10: Loss=2.1213, Val Acc=20.67%
[Worker 0] Epoch 10/10: Loss=2.1082, Val Acc=22.33%
[Worker 0] Training completed in 4.0s, Best Val Acc: 22.33%
[Worker 0] Config 3 started
[Worker 0] Params: {'config_id': 3, 'learning_rate': 0.0001, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.3259, Val Acc=7.00%
[Worker 0] Epoch 2/10: Loss=1.9804, Val Acc=24.67%
[Worker 0] Epoch 3/10: Loss=1.6891, Val Acc=37.33%
[Worker 0] Epoch 4/10: Loss=1.4663, Val Acc=37.00%
[Worker 0] Epoch 5/10: Loss=1.2584, Val Acc=43.33%
[Worker 0] Epoch 6/10: Loss=1.0629, Val Acc=44.33%
[Worker 0] Epoch 7/10: Loss=0.8889, Val Acc=44.00%
[Worker 0] Epoch 8/10: Loss=0.7461, Val Acc=45.33%
[Worker 0] Epoch 9/10: Loss=0.6247, Val Acc=45.67%
[Worker 0] Epoch 10/10: Loss=0.5241, Val Acc=46.00%
[Worker 0] Training completed in 4.1s, Best Val Acc: 46.00%
[Worker 0] Config 4 started
[Worker 0] Params: {'config_id': 4, 'learning_rate': 0.0003, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.4000, Val Acc=11.00%
[Worker 0] Epoch 2/10: Loss=2.2383, Val Acc=19.00%
[Worker 0] Epoch 3/10: Loss=2.1170, Val Acc=28.33%
[Worker 0] Epoch 4/10: Loss=1.9833, Val Acc=31.67%
[Worker 0] Epoch 5/10: Loss=1.8563, Val Acc=35.67%
[Worker 0] Epoch 6/10: Loss=1.7641, Val Acc=35.67%
[Worker 0] Epoch 7/10: Loss=1.6549, Val Acc=37.33%
[Worker 0] Epoch 8/10: Loss=1.5670, Val Acc=39.67%
[Worker 0] Epoch 9/10: Loss=1.4857, Val Acc=44.33%
[Worker 0] Epoch 10/10: Loss=1.3522, Val Acc=44.00%
[Worker 0] Training completed in 6.3s, Best Val Acc: 44.33%
[Worker 0] Config 5 started
[Worker 0] Params: {'config_id': 5, 'learning_rate': 0.0003, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.1038, Val Acc=26.33%
[Worker 0] Epoch 2/10: Loss=1.5059, Val Acc=42.67%
[Worker 0] Epoch 3/10: Loss=1.1451, Val Acc=43.67%
[Worker 0] Epoch 4/10: Loss=0.8641, Val Acc=49.33%
[Worker 0] Epoch 5/10: Loss=0.6591, Val Acc=49.67%
[Worker 0] Epoch 6/10: Loss=0.5259, Val Acc=53.67%
[Worker 0] Epoch 7/10: Loss=0.4283, Val Acc=52.67%
[Worker 0] Epoch 8/10: Loss=0.3550, Val Acc=53.00%
[Worker 0] Epoch 9/10: Loss=0.3416, Val Acc=49.33%
[Worker 0] Epoch 10/10: Loss=0.3130, Val Acc=52.67%
[Worker 0] Training completed in 6.6s, Best Val Acc: 53.67%
[Worker 0] Config 6 started
[Worker 0] Params: {'config_id': 6, 'learning_rate': 0.0003, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.4247, Val Acc=7.33%
[Worker 0] Epoch 2/10: Loss=2.3368, Val Acc=11.00%
[Worker 0] Epoch 3/10: Loss=2.1955, Val Acc=15.67%
[Worker 0] Epoch 4/10: Loss=2.1256, Val Acc=21.67%
[Worker 0] Epoch 5/10: Loss=2.0384, Val Acc=26.00%
[Worker 0] Epoch 6/10: Loss=1.9519, Val Acc=27.33%
[Worker 0] Epoch 7/10: Loss=1.8940, Val Acc=32.67%
[Worker 0] Epoch 8/10: Loss=1.8009, Val Acc=34.33%
[Worker 0] Epoch 9/10: Loss=1.7422, Val Acc=34.00%
[Worker 0] Epoch 10/10: Loss=1.6773, Val Acc=36.33%
[Worker 0] Training completed in 3.9s, Best Val Acc: 36.33%
[Worker 0] Config 7 started
[Worker 0] Params: {'config_id': 7, 'learning_rate': 0.0003, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.1789, Val Acc=17.33%
[Worker 0] Epoch 2/10: Loss=1.5568, Val Acc=41.33%
[Worker 0] Epoch 3/10: Loss=1.1208, Val Acc=50.33%
[Worker 0] Epoch 4/10: Loss=0.7963, Val Acc=52.00%
[Worker 0] Epoch 5/10: Loss=0.5339, Val Acc=54.33%
[Worker 0] Epoch 6/10: Loss=0.3960, Val Acc=52.67%
[Worker 0] Epoch 7/10: Loss=0.2822, Val Acc=52.33%
[Worker 0] Epoch 8/10: Loss=0.2221, Val Acc=52.33%
[Worker 0] Epoch 9/10: Loss=0.1947, Val Acc=53.00%
[Worker 0] Epoch 10/10: Loss=0.1845, Val Acc=55.00%
[Worker 0] Training completed in 4.1s, Best Val Acc: 55.00%
[Worker 0] Config 8 started
[Worker 0] Params: {'config_id': 8, 'learning_rate': 0.0005, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.3620, Val Acc=11.67%
[Worker 0] Epoch 2/10: Loss=2.1639, Val Acc=28.00%
[Worker 0] Epoch 3/10: Loss=1.9879, Val Acc=34.67%
[Worker 0] Epoch 4/10: Loss=1.7981, Val Acc=37.00%
[Worker 0] Epoch 5/10: Loss=1.6458, Val Acc=38.67%
[Worker 0] Epoch 6/10: Loss=1.4880, Val Acc=40.33%
[Worker 0] Epoch 7/10: Loss=1.3592, Val Acc=45.33%
[Worker 0] Epoch 8/10: Loss=1.2284, Val Acc=47.00%
[Worker 0] Epoch 9/10: Loss=1.1139, Val Acc=46.00%
[Worker 0] Epoch 10/10: Loss=0.9897, Val Acc=47.67%
[Worker 0] Training completed in 6.3s, Best Val Acc: 47.67%
[Worker 0] Config 9 started
[Worker 0] Params: {'config_id': 9, 'learning_rate': 0.0005, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.0008, Val Acc=34.33%
[Worker 0] Epoch 2/10: Loss=1.3465, Val Acc=50.00%
[Worker 0] Epoch 3/10: Loss=1.0724, Val Acc=48.33%
[Worker 0] Epoch 4/10: Loss=0.8220, Val Acc=54.67%
[Worker 0] Epoch 5/10: Loss=0.5780, Val Acc=53.00%
[Worker 0] Epoch 6/10: Loss=0.5350, Val Acc=52.00%
[Worker 0] Epoch 7/10: Loss=0.4806, Val Acc=52.67%
[Worker 0] Epoch 8/10: Loss=0.4092, Val Acc=51.67%
[Worker 0] Epoch 9/10: Loss=0.4267, Val Acc=56.67%
[Worker 0] Epoch 10/10: Loss=0.4484, Val Acc=54.00%
[Worker 0] Training completed in 6.6s, Best Val Acc: 56.67%
[Worker 0] Config 10 started
[Worker 0] Params: {'config_id': 10, 'learning_rate': 0.0005, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.4101, Val Acc=6.67%
[Worker 0] Epoch 2/10: Loss=2.2904, Val Acc=12.67%
[Worker 0] Epoch 3/10: Loss=2.1195, Val Acc=21.67%
[Worker 0] Epoch 4/10: Loss=2.0033, Val Acc=31.67%
[Worker 0] Epoch 5/10: Loss=1.8827, Val Acc=32.67%
[Worker 0] Epoch 6/10: Loss=1.7629, Val Acc=37.33%
[Worker 0] Epoch 7/10: Loss=1.6702, Val Acc=41.00%
[Worker 0] Epoch 8/10: Loss=1.5602, Val Acc=39.00%
[Worker 0] Epoch 9/10: Loss=1.4508, Val Acc=44.00%
[Worker 0] Epoch 10/10: Loss=1.3713, Val Acc=45.33%
[Worker 0] Training completed in 4.5s, Best Val Acc: 45.33%
[Worker 0] Config 11 started
[Worker 0] Params: {'config_id': 11, 'learning_rate': 0.0005, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.0690, Val Acc=21.33%
[Worker 0] Epoch 2/10: Loss=1.3698, Val Acc=44.67%
[Worker 0] Epoch 3/10: Loss=0.8852, Val Acc=53.33%
[Worker 0] Epoch 4/10: Loss=0.5586, Val Acc=49.67%
[Worker 0] Epoch 5/10: Loss=0.3486, Val Acc=51.00%
[Worker 0] Epoch 6/10: Loss=0.2759, Val Acc=51.00%
[Worker 0] Epoch 7/10: Loss=0.2211, Val Acc=53.00%
[Worker 0] Epoch 8/10: Loss=0.2406, Val Acc=50.00%
[Worker 0] Epoch 9/10: Loss=0.2944, Val Acc=52.00%
[Worker 0] Epoch 10/10: Loss=0.2576, Val Acc=47.00%
[Worker 0] Training completed in 4.1s, Best Val Acc: 53.33%
[Worker 0] Config 12 started
[Worker 0] Params: {'config_id': 12, 'learning_rate': 0.001, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.3247, Val Acc=17.00%
[Worker 0] Epoch 2/10: Loss=2.0439, Val Acc=27.00%
[Worker 0] Epoch 3/10: Loss=1.7933, Val Acc=34.33%
[Worker 0] Epoch 4/10: Loss=1.5436, Val Acc=41.00%
[Worker 0] Epoch 5/10: Loss=1.3125, Val Acc=46.33%
[Worker 0] Epoch 6/10: Loss=1.1049, Val Acc=46.67%
[Worker 0] Epoch 7/10: Loss=0.9791, Val Acc=45.33%
[Worker 0] Epoch 8/10: Loss=0.8625, Val Acc=43.67%
[Worker 0] Epoch 9/10: Loss=0.8933, Val Acc=45.33%
[Worker 0] Epoch 10/10: Loss=0.7805, Val Acc=43.33%
[Worker 0] Training completed in 6.4s, Best Val Acc: 46.67%
[Worker 0] Config 13 started
[Worker 0] Params: {'config_id': 13, 'learning_rate': 0.001, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=1.9166, Val Acc=38.67%
[Worker 0] Epoch 2/10: Loss=1.3839, Val Acc=50.67%
[Worker 0] Epoch 3/10: Loss=1.0551, Val Acc=51.00%
[Worker 0] Epoch 4/10: Loss=0.9323, Val Acc=52.33%
[Worker 0] Epoch 5/10: Loss=0.7890, Val Acc=50.00%
[Worker 0] Epoch 6/10: Loss=0.7039, Val Acc=54.67%
[Worker 0] Epoch 7/10: Loss=0.6240, Val Acc=53.67%
[Worker 0] Epoch 8/10: Loss=0.7319, Val Acc=50.00%
[Worker 0] Epoch 9/10: Loss=0.6079, Val Acc=56.00%
[Worker 0] Epoch 10/10: Loss=0.5638, Val Acc=56.67%
[Worker 0] Training completed in 6.7s, Best Val Acc: 56.67%
[Worker 0] Config 14 started
[Worker 0] Params: {'config_id': 14, 'learning_rate': 0.001, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.3857, Val Acc=9.67%
[Worker 0] Epoch 2/10: Loss=2.1872, Val Acc=18.00%
[Worker 0] Epoch 3/10: Loss=1.9788, Val Acc=31.67%
[Worker 0] Epoch 4/10: Loss=1.8023, Val Acc=36.67%
[Worker 0] Epoch 5/10: Loss=1.6182, Val Acc=36.67%
[Worker 0] Epoch 6/10: Loss=1.4195, Val Acc=40.67%
[Worker 0] Epoch 7/10: Loss=1.2887, Val Acc=41.00%
[Worker 0] Epoch 8/10: Loss=1.1288, Val Acc=43.33%
[Worker 0] Epoch 9/10: Loss=1.0092, Val Acc=44.33%
[Worker 0] Epoch 10/10: Loss=0.8847, Val Acc=44.33%
[Worker 0] Training completed in 3.9s, Best Val Acc: 44.33%
[Worker 0] Config 15 started
[Worker 0] Params: {'config_id': 15, 'learning_rate': 0.001, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=1.9329, Val Acc=32.33%
[Worker 0] Epoch 2/10: Loss=1.2775, Val Acc=45.00%
[Worker 0] Epoch 3/10: Loss=0.8031, Val Acc=53.00%
[Worker 0] Epoch 4/10: Loss=0.5896, Val Acc=47.00%
[Worker 0] Epoch 5/10: Loss=0.5485, Val Acc=44.67%
[Worker 0] Epoch 6/10: Loss=0.5276, Val Acc=49.67%
[Worker 0] Epoch 7/10: Loss=0.4700, Val Acc=51.67%
[Worker 0] Epoch 8/10: Loss=0.4741, Val Acc=53.67%
[Worker 0] Epoch 9/10: Loss=0.3733, Val Acc=53.67%
[Worker 0] Epoch 10/10: Loss=0.3181, Val Acc=49.33%
[Worker 0] Training completed in 4.0s, Best Val Acc: 53.67%
[Worker 0] Config 16 started
[Worker 0] Params: {'config_id': 16, 'learning_rate': 0.003, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.2324, Val Acc=20.00%
[Worker 0] Epoch 2/10: Loss=1.7432, Val Acc=35.67%
[Worker 0] Epoch 3/10: Loss=1.3730, Val Acc=43.33%
[Worker 0] Epoch 4/10: Loss=1.0929, Val Acc=49.00%
[Worker 0] Epoch 5/10: Loss=0.8464, Val Acc=55.00%
[Worker 0] Epoch 6/10: Loss=0.7048, Val Acc=50.00%
[Worker 0] Epoch 7/10: Loss=0.5533, Val Acc=53.33%
[Worker 0] Epoch 8/10: Loss=0.4591, Val Acc=51.33%
[Worker 0] Epoch 9/10: Loss=0.4386, Val Acc=51.33%
[Worker 0] Epoch 10/10: Loss=0.4505, Val Acc=51.00%
[Worker 0] Training completed in 6.4s, Best Val Acc: 55.00%
[Worker 0] Config 17 started
[Worker 0] Params: {'config_id': 17, 'learning_rate': 0.003, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.0346, Val Acc=21.67%
[Worker 0] Epoch 2/10: Loss=1.7470, Val Acc=32.33%
[Worker 0] Epoch 3/10: Loss=1.4837, Val Acc=30.00%
[Worker 0] Epoch 4/10: Loss=1.4958, Val Acc=41.00%
[Worker 0] Epoch 5/10: Loss=1.2675, Val Acc=44.33%
[Worker 0] Epoch 6/10: Loss=1.1830, Val Acc=40.67%
[Worker 0] Epoch 7/10: Loss=1.0719, Val Acc=47.33%
[Worker 0] Epoch 8/10: Loss=0.9501, Val Acc=46.33%
[Worker 0] Epoch 9/10: Loss=1.0123, Val Acc=43.67%
[Worker 0] Epoch 10/10: Loss=1.0962, Val Acc=45.00%
[Worker 0] Training completed in 6.7s, Best Val Acc: 47.33%
[Worker 0] Config 18 started
[Worker 0] Params: {'config_id': 18, 'learning_rate': 0.003, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.3067, Val Acc=14.33%
[Worker 0] Epoch 2/10: Loss=2.0062, Val Acc=25.00%
[Worker 0] Epoch 3/10: Loss=1.6577, Val Acc=37.33%
[Worker 0] Epoch 4/10: Loss=1.2786, Val Acc=45.33%
[Worker 0] Epoch 5/10: Loss=0.9807, Val Acc=47.33%
[Worker 0] Epoch 6/10: Loss=0.7241, Val Acc=50.67%
[Worker 0] Epoch 7/10: Loss=0.5562, Val Acc=52.33%
[Worker 0] Epoch 8/10: Loss=0.4028, Val Acc=52.33%
[Worker 0] Epoch 9/10: Loss=0.3245, Val Acc=49.00%
[Worker 0] Epoch 10/10: Loss=0.3047, Val Acc=53.33%
[Worker 0] Training completed in 3.9s, Best Val Acc: 53.33%
[Worker 0] Config 19 started
[Worker 0] Params: {'config_id': 19, 'learning_rate': 0.003, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.0089, Val Acc=24.33%
[Worker 0] Epoch 2/10: Loss=1.5623, Val Acc=37.00%
[Worker 0] Epoch 3/10: Loss=1.2433, Val Acc=38.33%
[Worker 0] Epoch 4/10: Loss=1.0962, Val Acc=45.33%
[Worker 0] Epoch 5/10: Loss=1.0011, Val Acc=44.33%
[Worker 0] Epoch 6/10: Loss=0.8702, Val Acc=46.00%
[Worker 0] Epoch 7/10: Loss=0.8900, Val Acc=44.00%
[Worker 0] Epoch 8/10: Loss=0.8774, Val Acc=49.33%
[Worker 0] Epoch 9/10: Loss=0.7677, Val Acc=46.67%
[Worker 0] Epoch 10/10: Loss=0.6523, Val Acc=47.33%
[Worker 0] Training completed in 4.2s, Best Val Acc: 49.33%
[Worker 0] Config 20 started
[Worker 0] Params: {'config_id': 20, 'learning_rate': 0.005, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.1586, Val Acc=31.00%
[Worker 0] Epoch 2/10: Loss=1.7245, Val Acc=39.33%
[Worker 0] Epoch 3/10: Loss=1.3898, Val Acc=43.00%
[Worker 0] Epoch 4/10: Loss=1.2366, Val Acc=44.33%
[Worker 0] Epoch 5/10: Loss=1.0419, Val Acc=47.33%
[Worker 0] Epoch 6/10: Loss=0.8649, Val Acc=45.33%
[Worker 0] Epoch 7/10: Loss=0.7790, Val Acc=46.33%
[Worker 0] Epoch 8/10: Loss=0.7740, Val Acc=47.33%
[Worker 0] Epoch 9/10: Loss=0.6998, Val Acc=41.33%
[Worker 0] Epoch 10/10: Loss=0.6482, Val Acc=45.67%
[Worker 0] Training completed in 6.2s, Best Val Acc: 47.33%
[Worker 0] Config 21 started
[Worker 0] Params: {'config_id': 21, 'learning_rate': 0.005, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.1267, Val Acc=13.67%
[Worker 0] Epoch 2/10: Loss=1.8535, Val Acc=29.67%
[Worker 0] Epoch 3/10: Loss=1.6784, Val Acc=32.33%
[Worker 0] Epoch 4/10: Loss=1.6148, Val Acc=30.67%
[Worker 0] Epoch 5/10: Loss=1.6272, Val Acc=30.00%
[Worker 0] Epoch 6/10: Loss=1.5362, Val Acc=30.33%
[Worker 0] Epoch 7/10: Loss=1.6010, Val Acc=25.00%
[Worker 0] Epoch 8/10: Loss=1.4913, Val Acc=30.67%
[Worker 0] Epoch 9/10: Loss=1.4544, Val Acc=36.67%
[Worker 0] Epoch 10/10: Loss=1.2830, Val Acc=32.33%
[Worker 0] Training completed in 7.2s, Best Val Acc: 36.67%
[Worker 0] Config 22 started
[Worker 0] Params: {'config_id': 22, 'learning_rate': 0.005, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.2528, Val Acc=17.67%
[Worker 0] Epoch 2/10: Loss=1.8710, Val Acc=33.33%
[Worker 0] Epoch 3/10: Loss=1.4992, Val Acc=33.00%
[Worker 0] Epoch 4/10: Loss=1.1137, Val Acc=42.00%
[Worker 0] Epoch 5/10: Loss=0.8337, Val Acc=44.00%
[Worker 0] Epoch 6/10: Loss=0.6185, Val Acc=46.67%
[Worker 0] Epoch 7/10: Loss=0.4530, Val Acc=47.00%
[Worker 0] Epoch 8/10: Loss=0.3442, Val Acc=46.67%
[Worker 0] Epoch 9/10: Loss=0.2983, Val Acc=47.33%
[Worker 0] Epoch 10/10: Loss=0.3562, Val Acc=52.33%
[Worker 0] Training completed in 4.1s, Best Val Acc: 52.33%
[Worker 0] Config 23 started
[Worker 0] Params: {'config_id': 23, 'learning_rate': 0.005, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.1424, Val Acc=12.33%
[Worker 0] Epoch 2/10: Loss=1.7983, Val Acc=22.00%
[Worker 0] Epoch 3/10: Loss=1.5774, Val Acc=35.67%
[Worker 0] Epoch 4/10: Loss=1.4549, Val Acc=35.67%
[Worker 0] Epoch 5/10: Loss=1.2980, Val Acc=42.67%
[Worker 0] Epoch 6/10: Loss=1.0871, Val Acc=37.33%
[Worker 0] Epoch 7/10: Loss=1.0928, Val Acc=37.33%
[Worker 0] Epoch 8/10: Loss=1.1222, Val Acc=35.00%
[Worker 0] Epoch 9/10: Loss=1.0564, Val Acc=37.67%
[Worker 0] Epoch 10/10: Loss=0.9582, Val Acc=41.00%
[Worker 0] Training completed in 4.0s, Best Val Acc: 42.67%
[Worker 0] Config 24 started
[Worker 0] Params: {'config_id': 24, 'learning_rate': 0.01, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.1732, Val Acc=20.00%
[Worker 0] Epoch 2/10: Loss=2.0135, Val Acc=22.33%
[Worker 0] Epoch 3/10: Loss=1.7208, Val Acc=31.67%
[Worker 0] Epoch 4/10: Loss=1.6169, Val Acc=36.33%
[Worker 0] Epoch 5/10: Loss=1.4623, Val Acc=42.00%
[Worker 0] Epoch 6/10: Loss=1.2605, Val Acc=42.67%
[Worker 0] Epoch 7/10: Loss=1.2144, Val Acc=42.00%
[Worker 0] Epoch 8/10: Loss=1.1371, Val Acc=38.67%
[Worker 0] Epoch 9/10: Loss=1.0090, Val Acc=44.67%
[Worker 0] Epoch 10/10: Loss=0.8414, Val Acc=39.33%
[Worker 0] Training completed in 6.2s, Best Val Acc: 44.67%
[Worker 0] Config 25 started
[Worker 0] Params: {'config_id': 25, 'learning_rate': 0.01, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.3800, Val Acc=12.67%
[Worker 0] Epoch 2/10: Loss=2.1771, Val Acc=17.00%
[Worker 0] Epoch 3/10: Loss=1.9896, Val Acc=14.00%
[Worker 0] Epoch 4/10: Loss=2.0234, Val Acc=25.00%
[Worker 0] Epoch 5/10: Loss=1.9304, Val Acc=20.33%
[Worker 0] Epoch 6/10: Loss=1.8494, Val Acc=26.00%
[Worker 0] Epoch 7/10: Loss=1.8460, Val Acc=18.33%
[Worker 0] Epoch 8/10: Loss=1.7395, Val Acc=22.67%
[Worker 0] Epoch 9/10: Loss=1.7500, Val Acc=31.00%
[Worker 0] Epoch 10/10: Loss=1.6338, Val Acc=23.33%
[Worker 0] Training completed in 6.6s, Best Val Acc: 31.00%
[Worker 0] Config 26 started
[Worker 0] Params: {'config_id': 26, 'learning_rate': 0.01, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.2290, Val Acc=27.00%
[Worker 0] Epoch 2/10: Loss=1.7446, Val Acc=37.00%
[Worker 0] Epoch 3/10: Loss=1.3162, Val Acc=42.67%
[Worker 0] Epoch 4/10: Loss=1.0017, Val Acc=48.67%
[Worker 0] Epoch 5/10: Loss=0.7784, Val Acc=50.33%
[Worker 0] Epoch 6/10: Loss=0.5339, Val Acc=50.67%
[Worker 0] Epoch 7/10: Loss=0.5070, Val Acc=48.00%
[Worker 0] Epoch 8/10: Loss=0.5449, Val Acc=50.67%
[Worker 0] Epoch 9/10: Loss=0.5634, Val Acc=47.00%
[Worker 0] Epoch 10/10: Loss=0.5323, Val Acc=46.00%
[Worker 0] Training completed in 3.8s, Best Val Acc: 50.67%
[Worker 0] Config 27 started
[Worker 0] Params: {'config_id': 27, 'learning_rate': 0.01, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.4557, Val Acc=8.67%
[Worker 0] Epoch 2/10: Loss=2.0640, Val Acc=5.67%
[Worker 0] Epoch 3/10: Loss=1.8913, Val Acc=15.00%
[Worker 0] Epoch 4/10: Loss=1.8619, Val Acc=26.33%
[Worker 0] Epoch 5/10: Loss=1.8702, Val Acc=34.00%
[Worker 0] Epoch 6/10: Loss=1.7849, Val Acc=28.00%
[Worker 0] Epoch 7/10: Loss=1.7038, Val Acc=26.33%
[Worker 0] Epoch 8/10: Loss=1.6255, Val Acc=34.00%
[Worker 0] Epoch 9/10: Loss=1.5774, Val Acc=19.67%
[Worker 0] Epoch 10/10: Loss=1.5974, Val Acc=25.67%
[Worker 0] Training completed in 4.2s, Best Val Acc: 34.00%
[Worker 0] Config 28 started
[Worker 0] Params: {'config_id': 28, 'learning_rate': 0.03, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.3274, Val Acc=10.33%
[Worker 0] Epoch 2/10: Loss=2.1666, Val Acc=22.33%
[Worker 0] Epoch 3/10: Loss=2.1476, Val Acc=22.67%
[Worker 0] Epoch 4/10: Loss=1.9982, Val Acc=17.33%
[Worker 0] Epoch 5/10: Loss=2.0039, Val Acc=25.00%
[Worker 0] Epoch 6/10: Loss=1.8410, Val Acc=24.33%
[Worker 0] Epoch 7/10: Loss=1.8565, Val Acc=24.67%
[Worker 0] Epoch 8/10: Loss=1.7455, Val Acc=27.00%
[Worker 0] Epoch 9/10: Loss=1.6836, Val Acc=30.33%
[Worker 0] Epoch 10/10: Loss=1.6115, Val Acc=27.00%
[Worker 0] Training completed in 6.3s, Best Val Acc: 30.33%
[Worker 0] Config 29 started
[Worker 0] Params: {'config_id': 29, 'learning_rate': 0.03, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.8364, Val Acc=9.00%
[Worker 0] Epoch 2/10: Loss=2.6310, Val Acc=11.00%
[Worker 0] Epoch 3/10: Loss=2.5812, Val Acc=13.33%
[Worker 0] Epoch 4/10: Loss=2.3147, Val Acc=12.67%
[Worker 0] Epoch 5/10: Loss=2.3022, Val Acc=17.00%
[Worker 0] Epoch 6/10: Loss=2.2931, Val Acc=18.67%
[Worker 0] Epoch 7/10: Loss=2.2797, Val Acc=13.00%
[Worker 0] Epoch 8/10: Loss=2.1885, Val Acc=16.67%
[Worker 0] Epoch 9/10: Loss=2.1405, Val Acc=21.33%
[Worker 0] Epoch 10/10: Loss=2.1072, Val Acc=17.67%
[Worker 0] Training completed in 6.6s, Best Val Acc: 21.33%
[Worker 0] Config 30 started
[Worker 0] Params: {'config_id': 30, 'learning_rate': 0.03, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.1731, Val Acc=8.00%
[Worker 0] Epoch 2/10: Loss=1.9856, Val Acc=21.33%
[Worker 0] Epoch 3/10: Loss=1.7193, Val Acc=23.33%
[Worker 0] Epoch 4/10: Loss=1.6436, Val Acc=29.33%
[Worker 0] Epoch 5/10: Loss=1.5617, Val Acc=36.00%
[Worker 0] Epoch 6/10: Loss=1.4207, Val Acc=34.33%
[Worker 0] Epoch 7/10: Loss=1.3829, Val Acc=33.33%
[Worker 0] Epoch 8/10: Loss=1.2093, Val Acc=38.33%
[Worker 0] Epoch 9/10: Loss=1.0385, Val Acc=38.67%
[Worker 0] Epoch 10/10: Loss=0.9993, Val Acc=39.67%
[Worker 0] Training completed in 3.9s, Best Val Acc: 39.67%
[Worker 0] Config 31 started
[Worker 0] Params: {'config_id': 31, 'learning_rate': 0.03, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0, 'fine_tuning': 'full'}
[Worker 0] CUDA is available. Using device: Tesla T4
[Worker 0] Using cached dataset
[Worker 0] Data prepared: 800 train samples
[Worker 0] Fine-tuning: Full
[Worker 0] Training started: 10 epochs
[Worker 0] Epoch 1/10: Loss=2.9344, Val Acc=9.67%
[Worker 0] Epoch 2/10: Loss=2.6498, Val Acc=12.00%
[Worker 0] Epoch 3/10: Loss=3.0384, Val Acc=10.00%
[Worker 0] Epoch 4/10: Loss=2.4239, Val Acc=10.67%
[Worker 0] Epoch 5/10: Loss=2.3260, Val Acc=18.33%
[Worker 0] Epoch 6/10: Loss=2.1911, Val Acc=18.67%
[Worker 0] Epoch 7/10: Loss=2.1182, Val Acc=21.67%
[Worker 0] Epoch 8/10: Loss=2.0881, Val Acc=23.67%
[Worker 0] Epoch 9/10: Loss=2.0559, Val Acc=22.67%
[Worker 0] Epoch 10/10: Loss=2.0077, Val Acc=21.67%
[Worker 0] Training completed in 4.1s, Best Val Acc: 23.67%

================================================================================
END OF REPORT
================================================================================
